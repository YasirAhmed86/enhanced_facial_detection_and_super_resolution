{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6f4b3a0-a2de-4359-b746-792371902768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\STARIZ.PK/.insightface\\models\\buffalo_l\\1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\STARIZ.PK/.insightface\\models\\buffalo_l\\2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\STARIZ.PK/.insightface\\models\\buffalo_l\\det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\STARIZ.PK/.insightface\\models\\buffalo_l\\genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\STARIZ.PK/.insightface\\models\\buffalo_l\\w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (640, 640)\n",
      "Processed and saved: F:\\super_resolution_project\\lr_imgs\\face_0_1066405,4b1ff0007e9d5ad6.jpg\n",
      "Processed and saved: F:\\super_resolution_project\\lr_imgs\\face_1_1066405,4b1ff0007e9d5ad6.jpg\n",
      "Processed and saved: F:\\super_resolution_project\\lr_imgs\\face_2_1066405,4b1ff0007e9d5ad6.jpg\n",
      "Processed and saved: F:\\super_resolution_project\\lr_imgs\\face_3_1066405,4b1ff0007e9d5ad6.jpg\n",
      "Processed and saved: F:\\super_resolution_project\\lr_imgs\\face_4_1066405,4b1ff0007e9d5ad6.jpg\n",
      "Processed and saved: F:\\super_resolution_project\\lr_imgs\\face_5_1066405,4b1ff0007e9d5ad6.jpg\n",
      "Processed and saved: F:\\super_resolution_project\\lr_imgs\\face_6_1066405,4b1ff0007e9d5ad6.jpg\n",
      "Processed and saved: F:\\super_resolution_project\\lr_imgs\\face_7_1066405,4b1ff0007e9d5ad6.jpg\n",
      "Processed and saved: F:\\super_resolution_project\\lr_imgs\\face_8_1066405,4b1ff0007e9d5ad6.jpg\n",
      "Processed and saved: F:\\super_resolution_project\\lr_imgs\\face_9_1066405,4b1ff0007e9d5ad6.jpg\n",
      "Processed and saved: F:\\super_resolution_project\\lr_imgs\\face_10_1066405,4b1ff0007e9d5ad6.jpg\n",
      "Processed and saved: F:\\super_resolution_project\\lr_imgs\\face_11_1066405,4b1ff0007e9d5ad6.jpg\n",
      "Processed and saved: F:\\super_resolution_project\\lr_imgs\\face_12_1066405,4b1ff0007e9d5ad6.jpg\n",
      "Processed and saved: F:\\super_resolution_project\\lr_imgs\\face_13_1066405,4b1ff0007e9d5ad6.jpg\n",
      "Processed and saved: F:\\super_resolution_project\\lr_imgs\\face_14_1066405,4b1ff0007e9d5ad6.jpg\n",
      "Processed and saved: F:\\super_resolution_project\\lr_imgs\\face_15_1066405,4b1ff0007e9d5ad6.jpg\n",
      "Processed and saved: F:\\super_resolution_project\\lr_imgs\\face_16_1066405,4b1ff0007e9d5ad6.jpg\n",
      "Processed and saved: F:\\super_resolution_project\\lr_imgs\\face_17_1066405,4b1ff0007e9d5ad6.jpg\n",
      "Processed and saved: F:\\super_resolution_project\\lr_imgs\\face_18_1066405,4b1ff0007e9d5ad6.jpg\n",
      "Processed and saved: F:\\super_resolution_project\\lr_imgs\\face_19_1066405,4b1ff0007e9d5ad6.jpg\n",
      "Processed and saved: F:\\super_resolution_project\\lr_imgs\\face_20_1066405,4b1ff0007e9d5ad6.jpg\n",
      "Processed and saved: F:\\super_resolution_project\\lr_imgs\\face_21_1066405,4b1ff0007e9d5ad6.jpg\n",
      "Processed and saved: F:\\super_resolution_project\\lr_imgs\\face_22_1066405,4b1ff0007e9d5ad6.jpg\n",
      "Cropped face 23 is empty in image F:\\super_resolution_project\\hr_imgs\\1066405,4b1ff0007e9d5ad6.jpg. Skipping...\n",
      "Processed and saved: F:\\super_resolution_project\\lr_imgs\\face_24_1066405,4b1ff0007e9d5ad6.jpg\n",
      "Processed and saved: F:\\super_resolution_project\\lr_imgs\\face_25_1066405,4b1ff0007e9d5ad6.jpg\n",
      "Processed and saved: F:\\super_resolution_project\\lr_imgs\\face_26_1066405,4b1ff0007e9d5ad6.jpg\n",
      "Processed and saved: F:\\super_resolution_project\\lr_imgs\\face_27_1066405,4b1ff0007e9d5ad6.jpg\n",
      "Processed and saved: F:\\super_resolution_project\\lr_imgs\\face_28_1066405,4b1ff0007e9d5ad6.jpg\n",
      "Processed and saved: F:\\super_resolution_project\\lr_imgs\\face_29_1066405,4b1ff0007e9d5ad6.jpg\n",
      "Processed and saved: F:\\super_resolution_project\\lr_imgs\\face_30_1066405,4b1ff0007e9d5ad6.jpg\n",
      "Processed and saved: F:\\super_resolution_project\\lr_imgs\\face_31_1066405,4b1ff0007e9d5ad6.jpg\n",
      "Processed and saved: F:\\super_resolution_project\\lr_imgs\\face_32_1066405,4b1ff0007e9d5ad6.jpg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from insightface.app import FaceAnalysis\n",
    "\n",
    "def load_model():\n",
    "    app = FaceAnalysis(name='buffalo_l', providers=['CUDAExecutionProvider', 'CPUExecutionProvider'])\n",
    "    app.prepare(ctx_id=0, det_size=(640, 640))\n",
    "    return app\n",
    "\n",
    "def apply_gaussian_blur(img, kernel_size=(5, 5)):\n",
    "    return cv2.GaussianBlur(img, kernel_size, 0)\n",
    "\n",
    "def add_gaussian_noise(img):\n",
    "    row, col, ch = img.shape\n",
    "    mean = 0\n",
    "    var = 0.1\n",
    "    sigma = var ** 0.5\n",
    "    gauss = np.random.normal(mean, sigma, (row, col, ch))\n",
    "    gauss = gauss.reshape(row, col, ch)\n",
    "    noisy_img = img + gauss * 255\n",
    "    return np.clip(noisy_img, 0, 255).astype(np.uint8)\n",
    "\n",
    "def detect_and_process_faces(model, img_path, output_folder, target_size=(128, 128)):\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        print(f\"Warning: Unable to load image at {img_path}. Skipping...\")\n",
    "        return\n",
    "    \n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    faces = model.get(img_rgb)\n",
    "    degraded_img = add_gaussian_noise(apply_gaussian_blur(img))\n",
    "\n",
    "    if not faces:\n",
    "        print(f\"No faces detected in {img_path}. Skipping...\")\n",
    "        return\n",
    "\n",
    "    for idx, face in enumerate(faces):\n",
    "        bbox = face.bbox.astype(int)\n",
    "        x1, y1, x2, y2 = bbox[0], bbox[1], bbox[2], bbox[3]\n",
    "\n",
    "        # Ensure the bounding box is valid\n",
    "        if x1 >= x2 or y1 >= y2:\n",
    "            print(f\"Invalid bounding box for face {idx} in image {img_path}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        cropped_face = degraded_img[y1:y2, x1:x2]\n",
    "\n",
    "        # Check if the cropped image is empty\n",
    "        if cropped_face.size == 0:\n",
    "            print(f\"Cropped face {idx} is empty in image {img_path}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Resize the cropped face to the target size\n",
    "        resized_face = cv2.resize(cropped_face, target_size)\n",
    "\n",
    "        face_path = os.path.join(output_folder, f\"face_{idx}_{os.path.basename(img_path)}\")\n",
    "        cv2.imwrite(face_path, resized_face)\n",
    "        print(f\"Processed and saved: {face_path}\")\n",
    "\n",
    "def main(input_folder, output_folder):\n",
    "    model = load_model()\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    for image_file in os.listdir(input_folder):\n",
    "        image_path = os.path.join(input_folder, image_file)\n",
    "        detect_and_process_faces(model, image_path, output_folder)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_folder = r'F:\\super_resolution_project\\hr_imgs'\n",
    "    output_folder = r'F:\\super_resolution_project\\lr_imgs'\n",
    "    main(input_folder, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f127da9f-6401-4c01-9af4-a60d5b5be215",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
