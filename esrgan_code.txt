code_1

import torch
from torch import nn
from torch.optim import Adam
from torchvision import transforms
from torchvision.utils import save_image
from torch.utils.data import DataLoader, Dataset
from PIL import Image
import os

class DatasetFromFolder(Dataset):
    def __init__(self, directory, input_transform=None, target_transform=None):
        super(DatasetFromFolder, self).__init__()
        self.directory = directory
        self.image_files = [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith(('.png', '.jpg', '.jpeg'))]
        self.input_transform = input_transform
        self.target_transform = target_transform

    def __len__(self):
        return len(self.image_files)

    def __getitem__(self, idx):
        img_path = self.image_files[idx]
        img = Image.open(img_path).convert('RGB')

        if self.input_transform:
            input_img = self.input_transform(img)
        else:
            input_img = img

        if self.target_transform:
            target_img = self.target_transform(img)
        else:
            target_img = img

        return input_img, target_img


class Generator(nn.Module):
    def __init__(self):
        super(Generator, self).__init__()
        self.model = nn.Sequential(
            nn.Conv2d(3, 64, 9, 1, 4),
            nn.PReLU(),
            nn.Conv2d(64, 128, 1),
            nn.PReLU(),
            nn.ConvTranspose2d(128, 64, 4, 2, 1),
            nn.PReLU(),
            nn.ConvTranspose2d(64, 32, 4, 2, 1),
            nn.PReLU(),
            nn.Conv2d(32, 3, 3, 1, 1),
            nn.Tanh()
        )
    def forward(self, x):
        return self.model(x)

class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()
        self.main = nn.Sequential(
            nn.Conv2d(3, 64, 3, padding=1),
            nn.LeakyReLU(0.2),
            nn.Conv2d(64, 128, 3, stride=2, padding=1),
            nn.LeakyReLU(0.2),
            nn.Conv2d(128, 256, 3, stride=2, padding=1),
            nn.LeakyReLU(0.2),
            nn.Conv2d(256, 512, 3, stride=2, padding=1),
            nn.LeakyReLU(0.2),
            nn.AdaptiveAvgPool2d(1)
        )
        self.fc = nn.Linear(512, 1)
        
    def forward(self, x):
        x = self.main(x)
        x = torch.flatten(x, 1)
        x = self.fc(x)
        return torch.sigmoid(x)

# Loss Function for Generator
class GeneratorLoss(nn.Module):
    def __init__(self):
        super(GeneratorLoss, self).__init__()
        self.mse_loss = nn.MSELoss()

    def forward(self, fake_out, fake_img, real_img):
        content_loss = self.mse_loss(fake_img, real_img)
        adversarial_loss = -torch.log(fake_out).mean()
        return content_loss + 0.001 * adversarial_loss

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Transformations
input_transform = transforms.Compose([
    transforms.Resize((64, 64)),  # Resize the image to 64x64 for input
    transforms.ToTensor(),  # Convert image to tensor
])

target_transform = transforms.Compose([
    transforms.Resize((256, 256)),  # Resize the image to 256x256 for target
    transforms.ToTensor(),  # Convert image to tensor
])

# Dataset and DataLoader
train_dataset = DatasetFromFolder(
    "F:\\super_resolution_project\\hr_crowd_img",
    input_transform=input_transform,
    target_transform=target_transform
)
train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)

# Model, Optimizers, and Loss Function Initialization
generator = Generator().to(device)
discriminator = Discriminator().to(device)
g_optimizer = Adam(generator.parameters(), lr=0.0002)
d_optimizer = Adam(discriminator.parameters(), lr=0.0002)
g_loss_fn = GeneratorLoss().to(device)

# Training Loop
num_epochs = 100
for epoch in range(num_epochs):
    for low_res, high_res in train_loader:
        low_res, high_res = low_res.to(device), high_res.to(device)
        
        discriminator.zero_grad()
        high_res_fake = generator(low_res).detach()
        real_output = discriminator(high_res)
        fake_output = discriminator(high_res_fake)
        d_loss_real = torch.log(real_output + 1e-8)
        d_loss_fake = torch.log(1.0 - fake_output + 1e-8)
        d_loss = -(d_loss_real + d_loss_fake).mean()
        d_loss.backward()
        d_optimizer.step()
        
        generator.zero_grad()
        high_res_fake = generator(low_res)
        fake_output = discriminator(high_res_fake)
        g_loss = g_loss_fn(fake_output, high_res_fake, high_res)
        g_loss.backward()
        g_optimizer.step()

        print(f"Epoch {epoch+1}: Gen Loss: {g_loss.item()}, Disc Loss: {d_loss.item()}")

torch.save(generator.state_dict(), 'generator.pth')
torch.save(discriminator.state_dict(), 'discriminator.pth')

from PIL import Image
import os
from torchvision import transforms
from torch.utils.data import Dataset

class DatasetFromFolder(Dataset):
    def __init__(self, directory, input_transform=None):
        super(DatasetFromFolder, self).__init__()
        self.directory = directory
        self.image_files = [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith(('.png', '.jpg', '.jpeg'))]
        self.input_transform = input_transform

    def __len__(self):
        return len(self.image_files)

    def __getitem__(self, idx):
        img_path = self.image_files[idx]
        img = Image.open(img_path).convert('RGB')

        # Apply transformation
        if self.input_transform:
            img = self.input_transform(img)
        else:
            img = transforms.ToTensor()(img)  # Fallback to default tensor conversion

        return img  # Return the transformed image as tensor

# Ensure the transformation is defined properly
input_transform = transforms.Compose([
    transforms.Resize((64, 64)),  # Adjust size as needed for your model input
    transforms.ToTensor(),  # Convert images to tensor
])

# Initialize your dataset
test_dataset = DatasetFromFolder(
    r"F:\super_resolution_project\noisy_cropped_faces_img",
    input_transform=input_transform
)

test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)

generator.eval()  # Ensure the model is in evaluation mode
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
generator.to(device)

output_directory = r"F:\super_resolution_project\super_resolution_images"
if not os.path.exists(output_directory):
    os.makedirs(output_directory)

with torch.no_grad():
    for i, low_res in enumerate(test_loader):  # low_res should now only be tensors
        low_res = low_res.to(device)
        high_res_fake = generator(low_res)
        save_path = os.path.join(output_directory, f'high_resolution_fake_img_{i}.png')
        save_image(high_res_fake, save_path)
        print(f"Saved image to: {save_path}")

print("\n", f"Task Done")




code_2

import torch
from torch import nn, optim
from torchvision import transforms, utils, models
from torch.utils.data import DataLoader, Dataset
from PIL import Image
import os

# Define Dataset
class DatasetFromFolder(Dataset):
    def __init__(self, directory, input_transform=None, target_transform=None):
        self.directory = directory
        self.image_files = [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith(('.png', '.jpg', '.jpeg'))]
        self.input_transform = input_transform
        self.target_transform = target_transform

    def __len__(self):
        return len(self.image_files)

    def __getitem__(self, idx):
        img_path = self.image_files[idx]
        img = Image.open(img_path).convert('RGB')
        input_img = self.input_transform(img) if self.input_transform else img
        target_img = self.target_transform(img) if self.target_transform else img
        return input_img, target_img

# Define Generator with Residual Blocks
class Generator(nn.Module):
    def __init__(self):
        super(Generator, self).__init__()
        self.model = nn.Sequential(
            nn.Conv2d(3, 64, 9, 1, 4),
            nn.PReLU(),
            self._make_layer(64, 64),
            nn.ConvTranspose2d(64, 32, 4, 2, 1),
            nn.PReLU(),
            nn.ConvTranspose2d(32, 16, 4, 2, 1),
            nn.PReLU(),
            nn.Conv2d(16, 3, 3, 1, 1),
            nn.Tanh()
        )
    
    def _make_layer(self, in_channels, out_channels, num_blocks=2):
        layers = []
        for _ in range(num_blocks):
            layers.append(nn.Conv2d(in_channels, out_channels, 3, 1, 1))
            layers.append(nn.PReLU())
        return nn.Sequential(*layers)
    
    def forward(self, x):
        return self.model(x)

# Define Discriminator
class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()
        self.main = nn.Sequential(
            nn.Conv2d(3, 64, 3, padding=1),
            nn.LeakyReLU(0.2),
            nn.Conv2d(64, 128, 3, stride=2, padding=1),
            nn.LeakyReLU(0.2),
            nn.Conv2d(128, 256, 3, stride=2, padding=1),
            nn.LeakyReLU(0.2),
            nn.Conv2d(256, 512, 3, stride=2, padding=1),
            nn.LeakyReLU(0.2),
            nn.AdaptiveAvgPool2d(1)
        )
        self.fc = nn.Linear(512, 1)
        
    def forward(self, x):
        x = self.main(x)
        x = torch.flatten(x, 1)
        x = self.fc(x)
        return torch.sigmoid(x)

# Perceptual Loss
class PerceptualLoss(nn.Module):
    def __init__(self):
        super(PerceptualLoss, self).__init__()
        vgg = models.vgg16(pretrained=True).features[:16]
        self.vgg = vgg.requires_grad_(False)
        self.mse_loss = nn.MSELoss()

    def forward(self, fake_img, real_img):
        fake_features = self.vgg(fake_img)
        real_features = self.vgg(real_img)
        return self.mse_loss(fake_features, real_features)

# Initialize device, models, loss functions, and optimizers
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
generator = Generator().to(device)
discriminator = Discriminator().to(device)
perceptual_loss = PerceptualLoss().to(device)
g_optimizer = optim.Adam(generator.parameters(), lr=0.0002)
d_optimizer = optim.Adam(discriminator.parameters(), lr=0.0002)
g_scheduler = optim.lr_scheduler.StepLR(g_optimizer, step_size=30, gamma=0.1)
d_scheduler = optim.lr_scheduler.StepLR(d_optimizer, step_size=30, gamma=0.1)

# Define transformations and dataloaders
input_transform = transforms.Compose([
    transforms.Resize((64, 64)),
    transforms.ToTensor(),
])

target_transform = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.ToTensor(),
])

train_dataset = DatasetFromFolder("F:\\super_resolution_project\\hr_crowd_img", input_transform=input_transform, target_transform=target_transform)
train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)

# Training parameters
num_epochs = 10  # Define the number of epochs

# Training loop
for epoch in range(num_epochs):
    for low_res, high_res in train_loader:
        low_res, high_res = low_res.to(device), high_res.to(device)

        # Discriminator training
        discriminator.zero_grad()
        high_res_fake = generator(low_res).detach()
        real_output = discriminator(high_res)
        fake_output = discriminator(high_res_fake)
        d_loss = -torch.log(real_output + 1e-8).mean() - torch.log(1.0 - fake_output + 1e-8).mean()
        d_loss.backward()
        d_optimizer.step()

        # Generator training
        generator.zero_grad()
        high_res_fake = generator(low_res)
        fake_output = discriminator(high_res_fake)
        p_loss = perceptual_loss(high_res_fake, high_res)
        g_loss = -torch.log(fake_output + 1e-8).mean() + p_loss
        g_loss.backward()
        g_optimizer.step()

    g_scheduler.step()
    d_scheduler.step()
    print(f"Epoch {epoch+1}: Gen Loss: {g_loss.item()}, Disc Loss: {d_loss.item()}")

# Save models
torch.save(generator.state_dict(), 'generator.pth')
torch.save(discriminator.state_dict(), 'discriminator.pth')

import os
import torch
from torch.utils.data import DataLoader, Dataset
from torchvision import transforms, utils
from PIL import Image

# Correctly import the save_image function
from torchvision.utils import save_image

class DatasetFromFolder(Dataset):
    def __init__(self, directory, input_transform=None):
        super(DatasetFromFolder, self).__init__()
        self.directory = directory
        self.image_files = [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith(('.png', '.jpg', '.jpeg'))]
        self.input_transform = input_transform

    def __len__(self):
        return len(self.image_files)

    def __getitem__(self, idx):
        img_path = self.image_files[idx]
        img = Image.open(img_path).convert('RGB')
        if self.input_transform:
            img = self.input_transform(img)
        else:
            img = transforms.ToTensor()(img)  # Fallback to default tensor conversion
        return img  # Return the transformed image as tensor

# Define the input transformation
input_transform = transforms.Compose([
    transforms.Resize((64, 64)),  # Adjust size as needed for your model input
    transforms.ToTensor(),  # Convert images to tensor
])

# Initialize your dataset
test_dataset = DatasetFromFolder(
    r"F:\super_resolution_project\noisy_cropped_faces_img",
    input_transform=input_transform
)

test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)

# Assuming 'generator' is already defined and loaded elsewhere in your script
generator.eval()  # Ensure the model is in evaluation mode
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
generator.to(device)

output_directory = r"F:\super_resolution_project\super_resolution_images"
if not os.path.exists(output_directory):
    os.makedirs(output_directory)

with torch.no_grad():
    for i, low_res in enumerate(test_loader):
        low_res = low_res.to(device)
        high_res_fake = generator(low_res)
        save_path = os.path.join(output_directory, f'high_resolution_fake_img_{i}.png')
        save_image(high_res_fake, save_path)
        print(f"Saved image to: {save_path}")

print("\nTask Done")
